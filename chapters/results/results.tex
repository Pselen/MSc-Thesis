\chapter{RESULTS}

\section{Evaluation}
Representation vectors for chemicals and proteins obtained using the aforementioned models and graphs, and then these vectors evaluated in the drug-target affinity task with the DeepDTA model using the BDB dataset. The DeepDTA model represents proteins using amino acid sequences and chemicals using characters of the SMILES notations. In this study, the DeepDTA model has been updated, as shown in Figure 3.3, to take as input the representation vectors containing additional information in the generated graphs. The performance of the model is measured by the Concordance Index (CI),  Mean Squared Error (MSE), Root Mean Squared Error (RMSE), and $R2$ metrics. 

% explain metrics with formula

\section{Experimental Setup}

As the training and test folds we use the same setup used in DeepDTA \cite{ozturk2018deepdta}. We train each model 5 times with the training set folds, then measure the performance on each test set, and report the average results on BDB. BDB dataset contains 5 different training sets and corresponding 4 different test sets as warm, cold ligand, cold protein and cold. The cold test sets contain data that was not used during the training of the model. We compute CI, MSE, RMSE, and $R^2$ scores of each model and report with the standard deviation.


\section{Model Comparisons}

\paragraph{Homogeneous ligand representation}
First, we generate homogeneous graphs with only one node and edge type, then test WideDeepDTA performance for the ligand representation.

\begin{itemize}
    \item \textbf{Model (1)}: A DDI (Drug-Drug Interaction) graph is created, the nodes of which are formed by all drugs (D) and the edges by interactions (D-D) between these drugs.   
    \item \textbf{Model (2)}: A DDI graph is created similar to Model (1), this time with the knowledge of initial embeddings of ChemBERTa model.
    \item \textbf{Model (3)}: A DDS (Drug-Drug Similarity) graph is created, the nodes of which are formed by all drugs (D) and the edges by Jaccard similarity between these drugs. 
    \item \textbf{Model (4)}: A DDS graph is created similar to Model (3), this time with the knowledge of initial embeddings of ChemBERTa model.
\end{itemize}

We first test the impact of ligand representation using homogeneous graphs by creating two different models with two different versions. Model (1) represents each drug with a 32-dimensional vector in which they are initialized as samples
from a uniform distribution over $[0, 1)$ and trained by metapath2vec model on DDI relation, and Model (2) represents each drug with the same dimensional size vector, however metapath2vec model's embeddings are initialized as ChemBERTa embeddings of corresponding ligands. (For the detailed results please refer to the Appendix \ref{app:homogeneous_ligand} and see Table \ref{tab:ddi_ci_r2} and Table \ref{tab:ddi_mse_rmse}.) On the other hand, Model (3) and Model (4) are trained on DDS relation with the same setup. (For the detailed results please refer to the Appendix \ref{app:homogeneous_ligand} and see Table \ref{tab:dds_ci_r2} and Table \ref{tab:dds_mse_rmse}.)

The results regarding the comparison of these four models are shown in Table \ref{tab:ddi_vs_dds_warm}, Table \ref{tab:ddi_vs_dds_cold_prot}, Table \ref{tab:ddi_vs_dds_cold_ligand}, and Table \ref{tab:ddi_vs_dds_cold_both}. Considering the results shown in Table \ref{tab:ddi_vs_dds_warm};
\begin{itemize}
    \item DDI models and DDS models perform similarly on the warm test set of BDB, \textit{i.e.}, their trends are the same for the same performance metrics. For instance, value of $R^2$ for models with PLMs is higher than the randomly initialized models, likewise MSE and RMSE values are lower for DDI and DDS models for the same case.
    \item Using PLM for drugs actually works since it increases the performance for three out of four metrics for both of the DDI and DDS models.
    \item As a result, we claim that, one can employ the similarity measures between two drugs when the interaction information is not available for these two drugs while using empowered homogeneous graphs on warm test set of BDB.
\end{itemize}

\input{chapters/results/tables/comparison_tables/ddi_dds/ddi_dds_warm}


As stated in the work of DeepDTA, CNN's ability to represent protein sequences is very low \cite{ozturk2018deepdta}. We initialized all the protein embeddings with zeros, since we do not train our models with any kinds of protein-related information. Considering the results shown in Table \ref{tab:ddi_vs_dds_cold_prot}, even initializing with zeros increases the performance for the DDI model. 


\input{chapters/results/tables/comparison_tables/ddi_dds/ddi_dds_cold_protein}

Taking into consideration the results shown in Table \ref{tab:ddi_vs_dds_cold_ligand} and Table \ref{tab:ddi_vs_dds_cold_both}, adding drug-related information using the homogeneous graph or empowered homogeneous graph did not improve the performance for the cold ligand and cold both test cases. However, results for cold both test set slightly better then the cold ligand test set due to the performance improvement of cold proteins. 

\input{chapters/results/tables/comparison_tables/ddi_dds/ddi_dds_cold_ligand}
\input{chapters/results/tables/comparison_tables/ddi_dds/ddi_dds_cold_both}

\paragraph{Homogeneous protein representation}
Second, we generate homogeneous graphs with only one node and edge type, then test WideDeepDTA performance for the protein representation.

\begin{itemize}
    \item \textbf{Model (5)}: A PPI (Protein-Protein Interaction) graph is created, the nodes of which are formed by all proteins (P) and the edges by interactions (P-P) between these proteins.   
    \item \textbf{Model (6)}: A PPI graph is created similar to Model (3), this time with the knowledge of initial embeddings of ProtBERT model.
    \item \textbf{Model (7)}: A PPS (Protein-Protein Similarity) graph is created, the nodes of which are formed by all proteins belonging to the human species (P) and the edges formed by the Jaccard similarities (P-P) between the amino acid sequences of these proteins. While calculating the similarities we tokenized each amino acid sequence using the glossary generated by BPE. Then we calculate the Paired Jaccard similarities of protein tokens. Considering the dataset, a threshold value is determined to cover at least 11\% of the data. Accordingly, protein pairs with similarity values greater than 9 determined to be similar to each other. 
    \item \textbf{Model (8)}: A PPS graph is created similar to Model (7), this time with the knowledge of initial embeddings of ProtBERT model.
\end{itemize}

First, we test the impact of protein representation using homogeneous graphs by creating two different models with two different versions. Model (5) represents each protein with a 32-dimensional vector in which they are initialized as samples from a uniform distribution over $[0, 1)$ and trained by metapath2vec model on PPI relation, and Model (6) represents each drug with the same dimensional size vector, however metapath2vec model's embeddings are initialized as ProtBERT embeddings of corresponding proteins. (For the detailed results please refer to the Appendix \ref{app:homogeneous_protein} and see Table \ref{tab:ppi_ci_r2} and Table \ref{tab:ppi_mse_rmse}.) On the other hand, Model (7) and Model (8) are trained on PPS relation with the same setup. (For the detailed results please refer to the Appendix \ref{app:homogeneous_protein} and see Table \ref{tab:pps_ci_r2} and Table \ref{tab:ppse_mse_rmse}.)

The results regarding the comparison of these four models are shown in Table \ref{tab:ppi_vs_pps_warm}, Table \ref{tab:ppi_vs_pps_cold_protein}, Table  \ref{tab:ppi_vs_pps_cold_ligand}, and Table \ref{tab:ppi_vs_pps_cold_both}. Considering the results shown in Table \ref{tab:ppi_vs_pps_warm};
\begin{itemize}
    \item Empowered graphs generated by PPS relation adds more information to the representation of proteins compared to the empowered graphs generated by PPI relation on warm test set. 
    \item In the case of PPI models, model with empowered graph performs better than the normal graphs in all metrics, except CI. However, both of them perform worse than the DeepDTA model on warm test set.
\end{itemize}

Considering the results shown in Table \ref{tab:ppi_vs_pps_cold_protein};
\begin{itemize}
    \item Empowered graphs generated by PPS relation adds more information to the representation of proteins compared to the empowered graphs generated by PPI relation on warm test set. 
    \item In the case of PPI models, model with empowered graph performs better than the normal graphs in all metrics, except CI. However, both of them perform worse than the DeepDTA model on warm test set.
\end{itemize}

\input{chapters/results/tables/comparison_tables/ppi_pps/ppi_pps_warm}

\paragraph{Heterogeneous representations}
Third, we generate heterogeneous graphs with several node and edge types, then test WideDeepDTA performance for the ligand representation.

\begin{itemize}
    \item \textbf{Model (9)} A DDiA (Drug-Disease Association) graph is created, the nodes of which are formed by all drugs (D), and diseases (Di) and the edges by association (D-Di) between these drugs and diseases.  
    \item \textbf{Model (10)} A DDiA graph is created similar to Model (9), this time with the knowledge of initial embeddings of ChemBERTa and BioBert models for SMILES sequences and disease names.
    \item \textbf{Model (15)} A DSA (Drug-Side Effect Association) graph is created, the nodes of which are formed by all drugs (D), and side effects (S) and the edges by association (D-S) between these drugs and side effects.  
    \item \textbf{Model (16)} A DSA graph is created similar to Model (15), this time with the knowledge of initial embeddings of ChemBERTa and BioBert models for SMILES sequences and side effect names.
    \item \textbf{Model (17)} A DDI-DSA (Drug-Drug Interaction \& Drug-Side Effect Association) graph is created, the nodes of which are formed by all drugs (D), and side effects (S) and the edges by association (D-D and D-S) between these drugs and side effects.  
    \item \textbf{Model (18)} A DDI-DSA graph is created similar to Model (17), this time with the knowledge of initial embeddings of ChemBERTa and BioBert models for SMILES sequences and side effect names.
\end{itemize}

\input{chapters/results/tables/result/ddia_ci_r2}
\input{chapters/results/tables/result/ddia_mse_rmse}
\input{chapters/results/tables/result/dsa_ci_r2}
\input{chapters/results/tables/result/dsa_mse_rmse}
\input{chapters/results/tables/result/ddi_dsa_ci_r2}
\input{chapters/results/tables/result/ddi_dsa_mse_rmse}

Fourth, we generate heterogeneous graphs with several node and edge types, then test WideDeepDTA performance for the protein representation.

\begin{itemize}
    \item \textbf{Model (11)} A PDiA (Protein-Disease Association) graph is created, the nodes of which are formed by all proteins (P) and diseases (Di) and the edges by association (P-Di) between these proteins and diseases.  
    \item \textbf{Model (12)} A PDiA graph is created similar to Model (11), this time with the knowledge of initial embeddings of ProtBERT and BioBert models for protein amino acid sequences and disease names respectively. 
\end{itemize}

Finally, we generate heterogeneous graphs with several node and edge types, then test WideDeepDTA performance for the both ligand and protein representation.

\begin{itemize}
    \item \textbf{Model (13)} A DDiPA (Drug-Disease-Protein Association) graph is created, the nodes of which are formed by all drugs (D), diseases (Di), proteins (P) and the edges by association (D-Di-P) between these drugs, proteins, and diseases.  
    \item \textbf{Model (14)} A DDiPA graph is created similar to Model (13), this time with the knowledge of initial embeddings of ChemBERTa, BioBert, and ProtBERT models for SMILES sequences, protein amino acid sequences, and disease names.
\end{itemize}

\input{chapters/results/tables/result/ddipa_ci_r2}
\input{chapters/results/tables/result/ddipa_mse_rmse}